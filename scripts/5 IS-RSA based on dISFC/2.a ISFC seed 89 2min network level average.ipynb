{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca163ae8-f6ee-4b23-a54d-17a07f3f302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac36384-8a15-49e0-9bee-b5839a92041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "import networkx as nx\n",
    "\n",
    "from numpy.fft import fft, ifft, fftfreq\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import rankdata, ttest_rel, ttest_1samp, pearsonr,spearmanr\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlinesÒ\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.plotting import plot_glass_brain, plot_stat_map, view_img, view_img_on_surf\n",
    "from nilearn.image import new_img_like\n",
    "\n",
    "from nltools.data import Brain_Data, Adjacency\n",
    "from nltools.mask import roi_to_brain, expand_mask\n",
    "from nltools.stats import isc, isfc\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21341e25-7ed5-4780-8b4c-4bee4765ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def regress_out(vec, control_matrices, upper_triangle_indices, standardize):\n",
    "    \"\"\"\n",
    "    对给定的向量进行回归，剥离控制变量的影响，先标准化再回归（可选）。\n",
    "    \n",
    "    参数:\n",
    "    - vec: np.array, 待剥离影响的向量\n",
    "    - control_matrices: list of np.array, 控制变量的矩阵列表\n",
    "    - upper_triangle_indices: tuple, 矩阵上三角的索引\n",
    "    - standardize: bool, 是否先标准化数据，默认值为 True\n",
    "    \n",
    "    返回:\n",
    "    - residuals: np.array, 回归后的残差\n",
    "    \"\"\"\n",
    "    if control_matrices is None or len(control_matrices) == 0:\n",
    "        return vec  # 如果没有控制变量，直接返回原始向量\n",
    "    \n",
    "    # 如果需要标准化，先标准化 vec\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        vec_scaled = scaler.fit_transform(vec.reshape(-1, 1)).flatten()\n",
    "    else:\n",
    "        vec_scaled = vec\n",
    "    \n",
    "    # 收集控制变量的标准化版本（如果需要）\n",
    "    control_vectors = []\n",
    "    for control_matrix in control_matrices:\n",
    "        control_vec = control_matrix[upper_triangle_indices]\n",
    "        if standardize:\n",
    "            control_vec_scaled = scaler.fit_transform(control_vec.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            control_vec_scaled = control_vec\n",
    "        control_vectors.append(control_vec_scaled)\n",
    "    \n",
    "    # 拼接控制变量矩阵\n",
    "    control_matrix = np.column_stack(control_vectors)\n",
    "\n",
    "    # 执行回归\n",
    "    model = LinearRegression().fit(control_matrix, vec_scaled)\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals = vec_scaled - model.predict(control_matrix)\n",
    "    \n",
    "    return residuals\n",
    "\n",
    "def mantel_with_multiple_controls(matrix1, matrix2, control_matrices=None, corr_type='spearman', permutations=1000, tail=2, standardize=True):\n",
    "    \"\"\"\n",
    "    执行带有多个控制变量的 Mantel Test，包含置换检验。\n",
    "    \n",
    "    参数:\n",
    "    - matrix1: np.array, 第一个距离矩阵 (NxN)\n",
    "    - matrix2: np.array, 第二个距离矩阵 (NxN)\n",
    "    - control_matrices: list of np.array, 控制变量的矩阵列表（默认为 None）\n",
    "    - permutations: int, 置换次数\n",
    "    - tail: int, p值的类型，1 表示单尾，2 表示双尾\n",
    "    \n",
    "    返回:\n",
    "    - r_obs: 观察到的 Pearson 或 Spearman 相关系数\n",
    "    - p_value: 置换检验的 p 值\n",
    "    \"\"\"\n",
    "    # 确保输入矩阵是方阵\n",
    "    assert matrix1.shape == matrix2.shape, \"两个矩阵的形状必须相同\"\n",
    "    assert matrix1.shape[0] == matrix1.shape[1], \"输入必须是方阵\"\n",
    "    \n",
    "    # 提取上三角部分（不包括对角线）\n",
    "    upper_triangle_indices = np.triu_indices_from(matrix1, k=1)\n",
    "    vec1 = matrix1[upper_triangle_indices]\n",
    "    vec2 = matrix2[upper_triangle_indices]\n",
    "    \n",
    "    # 对每个控制矩阵进行回归，剥离控制变量的影响\n",
    "    residuals1 = regress_out(vec1, control_matrices, upper_triangle_indices,standardize=standardize)\n",
    "    residuals2 = regress_out(vec2, control_matrices, upper_triangle_indices,standardize=standardize)\n",
    "    \n",
    "    # 计算观察到的相关系数\n",
    "    if corr_type == 'pearson':\n",
    "        r_obs, _ = pearsonr(residuals1, residuals2)\n",
    "    elif corr_type == 'spearman':\n",
    "        r_obs, _ = spearmanr(residuals1, residuals2)\n",
    "    \n",
    "    # 进行置换检验\n",
    "    permuted_r = []\n",
    "    n = matrix1.shape[0]\n",
    "    \n",
    "    for _ in range(permutations):\n",
    "        # 随机打乱行列索引\n",
    "        perm_indices = np.random.permutation(n)\n",
    "        \n",
    "        # 重新排列矩阵\n",
    "        perm_matrix2 = matrix2[np.ix_(perm_indices, perm_indices)]\n",
    "        \n",
    "        # 对每个控制变量矩阵也进行相同的置换（如果存在控制变量）\n",
    "        perm_control_matrices = []\n",
    "        if control_matrices is not None:\n",
    "            for control_matrix in control_matrices:\n",
    "                perm_control_matrix = control_matrix[np.ix_(perm_indices, perm_indices)]\n",
    "                perm_control_matrices.append(perm_control_matrix)\n",
    "        \n",
    "        # 提取置换后的上三角部分\n",
    "        perm_vec2 = perm_matrix2[upper_triangle_indices]\n",
    "        \n",
    "        # 对置换后的矩阵进行回归，剥离控制变量的影响\n",
    "        perm_residuals2 = regress_out(perm_vec2, perm_control_matrices, upper_triangle_indices, standardize=standardize)\n",
    "        \n",
    "        # 计算置换后的相关系数\n",
    "        if corr_type == 'pearson':\n",
    "            r_perm, _ = pearsonr(residuals1, perm_residuals2)\n",
    "        elif corr_type == 'spearman':\n",
    "            r_perm, _ = spearmanr(residuals1, perm_residuals2)\n",
    "        \n",
    "        permuted_r.append(r_perm)\n",
    "    \n",
    "    # 计算双尾或单尾 p 值\n",
    "    p_value = _calc_pvalue(np.array(permuted_r), r_obs, tail)\n",
    "    \n",
    "    return r_obs, p_value\n",
    "\n",
    "def _calc_pvalue(all_p, stat, tail):\n",
    "    \"\"\"计算基于置换分布的 p 值\n",
    "    \n",
    "    参数：\n",
    "    - all_p: 置换分布的相关系数列表\n",
    "    - stat: 观察到的统计量（如统计结果中的相关系数）\n",
    "    - tail: (int) 1 或 2，表示单尾或双尾 p 值\n",
    "    \n",
    "    返回：\n",
    "    - p_value: 计算得到的 p 值\n",
    "    \"\"\"\n",
    "    denom = float(len(all_p)) + 1\n",
    "    if tail == 1:\n",
    "        numer = np.sum(all_p >= stat) + 1 if stat >= 0 else np.sum(all_p <= stat) + 1\n",
    "    elif tail == 2:\n",
    "        numer = np.sum(np.abs(all_p) >= np.abs(stat)) + 1\n",
    "    else:\n",
    "        raise ValueError(\"tail 必须是 1 或 2\")\n",
    "    return numer / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77b50c3-6530-4968-a402-a86b82bb7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = '/Users/li/Desktop/debate/braindata'\n",
    "\n",
    "sub_list = [f'sub-{x:0>3d}' for x in range(13,51)]\n",
    "sub_list.remove('sub-021')\n",
    "\n",
    "subs_roi_data = []\n",
    "for sub in sub_list:\n",
    "    csv_file = f'/Volumes/Li/task-debate/braindata/denoised 5/parcel data/Schaefer 200 combine 6 runs/{sub}_combined_time-series_Schaefer2018_200Parcels_7Networks.csv'\n",
    "    sub_data = pd.read_csv(csv_file)\n",
    "    subs_roi_data.append(sub_data.values)\n",
    "\n",
    "all_brain_data = np.array(subs_roi_data)\n",
    "\n",
    "mask_file = '/Users/li/Desktop/template/Schaefer/tpl-MNI152NLin2009cAsym_res-02_atlas-Schaefer2018_desc-200Parcels7Networks_dseg.nii.gz'\n",
    "mask_img = nib.load(mask_file)\n",
    "mask_data = mask_img.get_fdata()\n",
    "\n",
    "nw_labels = pd.read_csv('/Users/li/Desktop/template/Schaefer/Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm.Centroid_RAS.csv')\n",
    "roi_name = list(nw_labels['ROI Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "028e7f6f-39f8-468f-be97-bdde0a1774a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 25)\n",
      "(37, 37)\n"
     ]
    }
   ],
   "source": [
    "bahav_data_dir = '/Users/li/Desktop/task-debate/behavdata'\n",
    "\n",
    "sub_list_num = list(range(13,51))\n",
    "sub_list_num.remove(21)\n",
    "\n",
    "# time_points = list(range(0,3000,60)) + [2986]  # every 1 minute\n",
    "time_points = list(range(0,3000,120)) + [2986] # every 2 min\n",
    "# time_points = list(range(0,3000,300)) + [2986] # every 5 min\n",
    "# time_points = [0, 252, 500, 772, 1098, 1484, 1892, 2464, 2986] # every speaker\n",
    "# time_points = list(range(0,2987,2)) # every TR\n",
    "\n",
    "# time_points = [0,80,168,208,252, \n",
    "#                326,364,464,500,\n",
    "#                538,588,686,772,\n",
    "#                860,986,1026,1098,\n",
    "#                1204,1250,1406,1484,\n",
    "#                1578,1722,1810,1892,\n",
    "#                1972,2114,2216,2464,\n",
    "#                2628,2756,2986] \n",
    "\n",
    "all_subject_data = []\n",
    "for sub in sub_list_num:\n",
    "    file_path = os.path.join(bahav_data_dir, 'during_scan', 'combined_6runs_per_TR_filter', f'subject_{sub}_TR_rate.csv')\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    sub_data = df[df['time'].isin(time_points)]\n",
    "    all_subject_data.append(list(sub_data['rate']))\n",
    "    \n",
    "attitude = pd.DataFrame(all_subject_data)\n",
    "\n",
    "start_attitude = pd.DataFrame(attitude)[0]\n",
    "start_attitude_SM = -np.abs(start_attitude.values[:, np.newaxis] - start_attitude.values)\n",
    "\n",
    "attitude_change = attitude.diff(axis=1)\n",
    "attitude_change = attitude_change.drop(attitude_change.columns[0], axis=1)\n",
    "print(attitude_change.shape)\n",
    "\n",
    "attitude_change_distances = -pdist(attitude_change)\n",
    "# attitude_change_distances = -np.sqrt(pdist(attitude_change))\n",
    "# attitude_change_distances = -np.log(pdist(attitude_change))\n",
    "attitude_change_SM = squareform(attitude_change_distances)\n",
    "print(attitude_change_SM.shape)\n",
    "\n",
    "# sns.heatmap(attitude_change_SM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b194f2-e234-4ada-b23b-2d9c7d23efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = list(range(13,51))\n",
    "subjects.remove(21)\n",
    "\n",
    "personality = pd.read_csv('/Users/li/Desktop/task-debate/behavdata/questionire_data/personality.csv')\n",
    "\n",
    "selected_data = personality[personality['sub'].isin(subjects)]\n",
    "selected_data = selected_data.set_index('sub').loc[subjects]\n",
    "\n",
    "ages = selected_data['age'].values\n",
    "age_diff_matrix = np.abs(ages[:, np.newaxis] - ages)\n",
    "\n",
    "sex = selected_data['sex'].values\n",
    "sex_diff_matrix = np.abs(sex[:, np.newaxis] - sex)\n",
    "\n",
    "IUS = selected_data['IUS'].values\n",
    "joint_IUS = (IUS[:, np.newaxis] + IUS)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f181fa-b6aa-4080-9829-95877cd36711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 37, 37)\n"
     ]
    }
   ],
   "source": [
    "subs_dISFC = np.load('/Users/li/Desktop/debate2025/results/subs_dISFC_seed89.npy')\n",
    "subs_dISFC = np.arctanh(subs_dISFC)\n",
    "\n",
    "intersub_dISFC_similarity = []\n",
    "for edge in range(subs_dISFC.shape[1]):\n",
    "    intersub_dISFC_similarity .append(Adjacency(1 - pairwise_distances(subs_dISFC[:, edge, :], metric='correlation'), matrix_type='similarity'))\n",
    "brain_ISC = Adjacency(intersub_dISFC_similarity )\n",
    "\n",
    "brain_ISC_np = np.array(brain_ISC.squareform())\n",
    "print(brain_ISC_np.shape)\n",
    "\n",
    "brain_ISC_Z_np = np.arctanh(brain_ISC_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad23ae76-fa3d-4d8e-9470-15e2d89712fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "nw_labels = pd.read_csv('/Users/li/Desktop/template/Schaefer/Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm.Centroid_RAS.csv')\n",
    "roi_name = list(nw_labels['ROI Name'])\n",
    "roi_name.remove(roi_name[89])\n",
    "print(len(roi_name))\n",
    "\n",
    "# 按照组别分组 (例如: Vis)\n",
    "groups = {}\n",
    "for roi in roi_name:\n",
    "    group_name = roi.split('_')[2]  # 假设组别是第三个部分，格式为: 7Networks_LH_Vis_1\n",
    "    if group_name not in groups:\n",
    "        groups[group_name] = []\n",
    "    groups[group_name].append(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74274f60-7cec-4a1f-b123-2e9f0e9a36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_labels = pd.read_csv('/Users/li/Desktop/template/Schaefer/Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm.Centroid_RAS.csv')\n",
    "nw_labels = nw_labels[nw_labels[\"ROI Label\"] != 90].reset_index(drop=True)\n",
    "\n",
    "vis, sm, da, va, limb, cont, default = [],[],[],[],[],[],[]\n",
    "for i in range(199):\n",
    "    net_name = nw_labels['ROI Name'][i].split('_')[2] \n",
    "    if net_name == 'Vis':\n",
    "        vis.append(i)\n",
    "    elif net_name == 'SomMot':\n",
    "        sm.append(i)\n",
    "    elif net_name == 'DorsAttn':\n",
    "        da.append(i)\n",
    "    elif net_name == 'SalVentAttn':\n",
    "        va.append(i)\n",
    "    elif net_name == 'Limbic':\n",
    "        limb.append(i)\n",
    "    elif net_name == 'Cont':\n",
    "        cont.append(i)\n",
    "    elif net_name == 'Default':\n",
    "        default.append(i)\n",
    "        \n",
    "nets = [vis, sm, da, va, limb, cont, default]\n",
    "nets_name = ['vis', 'sm', 'da', 'va', 'limb', 'cont', 'default']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e31b477-b83d-4ad5-9452-c665d7e06729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vis 0.07580516738569036 0.4106589341065893\n",
      "sm 0.06300149773185683 0.5002499750024998\n",
      "da 0.10524309640182725 0.2518748125187481\n",
      "va 0.11911016987431332 0.15898410158984103\n",
      "limb 0.11600454690685309 0.16818318168183183\n",
      "cont 0.15071627098670168 0.100989901009899\n",
      "default 0.21332388690462978 0.014898510148985102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rlist1, plist1 = [],[]\n",
    "for i, net in enumerate(nets):\n",
    "    net_ISC_mean = brain_ISC_Z_np[net,:,:].mean(0)\n",
    "    \n",
    "    r, p = mantel_with_multiple_controls(attitude_change_SM, net_ISC_mean,\n",
    "                                        standardize=True, corr_type='pearson',\n",
    "                                        control_matrices = [start_attitude_SM, sex_diff_matrix, age_diff_matrix], \n",
    "                                        permutations=10000,tail=2)\n",
    "    print(nets_name[i], r, p )\n",
    "    rlist1.append(r)\n",
    "    plist1.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87bb7ef5-45cc-4e13-a7ed-a490594b4913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vis 0.08155406479417061 0.37466253374662534\n",
      "sm 0.06999784586397892 0.4550544945505449\n",
      "da 0.1126259732124414 0.21957804219578042\n",
      "va 0.12531280798232255 0.14388561143885611\n",
      "limb 0.12064953816572696 0.1566843315668433\n",
      "cont 0.16109132565647394 0.0832916708329167\n",
      "default 0.2214124786848653 0.0160983901609839\n"
     ]
    }
   ],
   "source": [
    "rlist2, plist2 = [],[]\n",
    "for i, net in enumerate(nets):\n",
    "    net_ISC_mean = brain_ISC_Z_np[net,:,:].mean(0)\n",
    "    r, p = mantel_with_multiple_controls(attitude_change_SM, net_ISC_mean,\n",
    "                                        standardize=True, corr_type='pearson',\n",
    "                                        # control_matrices = [start_attitude_SM, sex_diff_matrix, age_diff_matrix], \n",
    "                                        permutations=10000,tail=2)\n",
    "    print(nets_name[i], r, p )\n",
    "    rlist2.append(r)\n",
    "    plist2.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96965f09-38af-401c-bcee-caef14f2e335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vis 0.05999477948439965 0.4958504149585041\n",
      "sm 0.07762463716954536 0.38986101389861016\n",
      "da 0.11054008653934387 0.2156784321567843\n",
      "va 0.11978055960868467 0.14588541145885411\n",
      "limb 0.11402304361137294 0.16318368163183683\n",
      "cont 0.14206752830258124 0.11458854114588542\n",
      "default 0.2005440056327875 0.0235976402359764\n"
     ]
    }
   ],
   "source": [
    "rlist3, plist3 = [],[]\n",
    "for i, net in enumerate(nets):\n",
    "    net_ISC_mean = brain_ISC_Z_np[net,:,:].mean(0)\n",
    "    r, p = mantel_with_multiple_controls(attitude_change_SM, net_ISC_mean,\n",
    "                                        standardize=True, corr_type='spearman',\n",
    "                                        control_matrices = [start_attitude_SM, sex_diff_matrix, age_diff_matrix], \n",
    "                                        permutations=10000,tail=2)\n",
    "    print(nets_name[i], r, p )\n",
    "    rlist3.append(r)\n",
    "    plist3.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2f5c221-48c9-4dd2-8d60-1861fa2062ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vis 0.062407186151580474 0.49695030496950304\n",
      "sm 0.08295396810678403 0.3575642435756424\n",
      "da 0.11367277382513927 0.20607939206079393\n",
      "va 0.12258415140100967 0.14088591140885912\n",
      "limb 0.11507576675901234 0.1655834416558344\n",
      "cont 0.1451256768278226 0.11408859114088592\n",
      "default 0.2061849969105771 0.0226977302269773\n"
     ]
    }
   ],
   "source": [
    "rlist4, plist4 = [],[]\n",
    "for i, net in enumerate(nets):\n",
    "    net_ISC_mean = brain_ISC_Z_np[net,:,:].mean(0)\n",
    "    r, p = mantel_with_multiple_controls(attitude_change_SM, net_ISC_mean,\n",
    "                                        standardize=True, corr_type='spearman',\n",
    "                                        # control_matrices = [start_attitude_SM, sex_diff_matrix, age_diff_matrix], \n",
    "                                        permutations=10000,tail=2)\n",
    "    print(nets_name[i], r, p )\n",
    "    rlist4.append(r)\n",
    "    plist4.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc4cb0e8-3b96-4613-8e9d-4b0f83b22e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = {\n",
    "    'pearson control': rlist1,\n",
    "    'p1': plist1,\n",
    "    'pearson no-control': rlist2,\n",
    "    'p2': plist2,\n",
    "    'spearman control': rlist3,\n",
    "    'p3': plist3,\n",
    "    'spearman no-control': rlist4,\n",
    "    'p4': plist4\n",
    "}\n",
    "\n",
    "result_data_df = pd.DataFrame(result_data)\n",
    "\n",
    "result_data_df.to_csv('/Users/li/Desktop/debate2025/results/ISFC-ISRSA-Exp1-seed89-2min-network-level.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
