{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14ad8475-b3bb-4d1c-9136-f485ce5b02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 1494)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "bahav_data_dir = '/Users/li/Desktop/task-debate/behavdata'\n",
    "\n",
    "sub_list_num = list(range(13,51))\n",
    "sub_list_num.remove(21)\n",
    "\n",
    "time_points = list(range(0,2986,2)) + [2986]  # every TR minute\n",
    "all_subject_data = []\n",
    "for sub in sub_list_num:\n",
    "    file_path = os.path.join(bahav_data_dir, 'during_scan', 'combined_6runs_per_TR_filter', f'subject_{sub}_TR_rate.csv')\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    sub_data = df[df['time'].isin(time_points)]\n",
    "    all_subject_data.append(list(sub_data['rate']))\n",
    "\n",
    "attitude = pd.DataFrame(all_subject_data)\n",
    "print(attitude.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25b83054-e564-4ee0-b530-ef471ffecedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 1493)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attitude_change_point = attitude.diff(axis=1)\n",
    "attitude_change_point = attitude_change_point.drop(attitude_change_point.columns[0], axis=1)\n",
    "df_binary = (attitude_change_point != 0).astype(int)\n",
    "subs_change_points = np.array(df_binary)\n",
    "subs_change_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33221d16-b1b6-4c88-9965-847ac5f6f35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 1485)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "remove_times = np.array([125,  249,  385,  548,  741,  945, 1231, 1492])\n",
    "\n",
    "# 计算需要删除的时间点的索引\n",
    "# 假设时间点范围是从 0 到 1000，找到对应列索引\n",
    "remove_indices = remove_times[remove_times < subs_change_points.shape[1]]  # 确保索引在有效范围内\n",
    "\n",
    "# 删除这些列的数据\n",
    "subs_change_points = np.delete(subs_change_points, remove_indices, axis=1)\n",
    "\n",
    "# 输出处理后的 subs_change_points 的形状\n",
    "print(subs_change_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d411e65-0d4d-4e47-ad16-91a31549d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Mean      Std  Min  Max  Median  25th Percentile  75th Percentile\n",
      "0  17.108108  12.8332    1   55    12.0              8.0             28.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "change_point_counts = np.sum(subs_change_points, axis=1)\n",
    "\n",
    "# 计算描述统计数据\n",
    "desc_stats = {\n",
    "    'Mean': np.mean(change_point_counts),\n",
    "    'Std': np.std(change_point_counts),\n",
    "    'Min': np.min(change_point_counts),\n",
    "    'Max': np.max(change_point_counts),\n",
    "    'Median': np.median(change_point_counts),\n",
    "    '25th Percentile': np.percentile(change_point_counts, 25),\n",
    "    '75th Percentile': np.percentile(change_point_counts, 75)\n",
    "}\n",
    "\n",
    "# 转换为 pandas DataFrame，方便查看\n",
    "desc_stats_df = pd.DataFrame([desc_stats])\n",
    "\n",
    "print(desc_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "49d1cc4a-08e7-4623-9528-ed3326efe92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Mean Dice Coefficient: 0.01905419617094492\n",
      "P-value from Randomization Test: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_subjects = subs_change_points.shape[0]\n",
    "dice_matrix = np.zeros((num_subjects, num_subjects))\n",
    "\n",
    "# 计算每对被试的Dice系数\n",
    "for i in range(num_subjects):\n",
    "    for j in range(i, num_subjects):\n",
    "        intersection = np.sum(np.logical_and(subs_change_points[i], subs_change_points[j]))\n",
    "        union = np.sum(np.logical_or(subs_change_points[i], subs_change_points[j]))\n",
    "        # 计算Dice系数\n",
    "        dice_coefficient = 2 * intersection / (np.sum(subs_change_points[i]) + np.sum(subs_change_points[j]))\n",
    "        dice_matrix[i, j] = dice_coefficient\n",
    "        dice_matrix[j, i] = dice_coefficient\n",
    "\n",
    "# 计算原始数据的平均Dice系数（只计算上三角，不包括对角线）\n",
    "original_mean_dice = np.mean(dice_matrix[np.triu_indices(num_subjects, k=1)])\n",
    "\n",
    "# 随机化检验\n",
    "n_permutations = 1000  # 设置随机化次数\n",
    "permutation_means = []\n",
    "\n",
    "# 执行随机化检验\n",
    "for _ in range(n_permutations):\n",
    "    # 创建一个副本，不影响原始数据\n",
    "    permuted_data = np.copy(subs_change_points)\n",
    "    \n",
    "    # 对每个被试独立打乱其变化点顺序\n",
    "    for i in range(num_subjects):\n",
    "        np.random.shuffle(permuted_data[i])  # 对每个被试的数据进行独立打乱\n",
    "    \n",
    "    # 重新计算随机化数据的Dice系数矩阵\n",
    "    # 重新计算随机化数据的Dice系数矩阵\n",
    "    permuted_dice_matrix = np.zeros((num_subjects, num_subjects))\n",
    "    for i in range(num_subjects):\n",
    "        for j in range(i, num_subjects):\n",
    "            intersection = np.sum(np.logical_and(permuted_data[i], permuted_data[j]))\n",
    "            union = np.sum(np.logical_or(permuted_data[i], permuted_data[j]))\n",
    "            permuted_dice_matrix[i, j] = 2 * intersection / (np.sum(permuted_data[i]) + np.sum(permuted_data[j]))\n",
    "            permuted_dice_matrix[j, i] = permuted_dice_matrix[i, j]\n",
    "    \n",
    "    # 计算随机化后的平均Dice系数\n",
    "    permuted_mean_dice = np.mean(permuted_dice_matrix[np.triu_indices(num_subjects, k=1)])\n",
    "    permutation_means.append(permuted_mean_dice)\n",
    "\n",
    "# 计算p值\n",
    "permutation_means = np.array(permutation_means)\n",
    "p_value = np.mean(permutation_means >= original_mean_dice)\n",
    "\n",
    "# 输出原始均值和p值\n",
    "print(f\"Original Mean Dice Coefficient: {original_mean_dice}\")\n",
    "print(f\"P-value from Randomization Test: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2d76ddb7-9ad6-4b16-87f0-269e49e0d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Median Dice Coefficient: 0.0\n",
      "P-value from Randomization Test: 1.0\n"
     ]
    }
   ],
   "source": [
    "num_subjects = subs_change_points.shape[0]\n",
    "dice_matrix = np.zeros((num_subjects, num_subjects))\n",
    "\n",
    "# 计算每对被试的Dice系数\n",
    "for i in range(num_subjects):\n",
    "    for j in range(i, num_subjects):\n",
    "        intersection = np.sum(np.logical_and(subs_change_points[i], subs_change_points[j]))\n",
    "        union = np.sum(np.logical_or(subs_change_points[i], subs_change_points[j]))\n",
    "        # 计算Dice系数\n",
    "        dice_coefficient = 2 * intersection / (np.sum(subs_change_points[i]) + np.sum(subs_change_points[j]))\n",
    "        dice_matrix[i, j] = dice_coefficient\n",
    "        dice_matrix[j, i] = dice_coefficient\n",
    "\n",
    "# 计算原始数据的中位数Dice系数（只计算上三角，不包括对角线）\n",
    "original_median_dice = np.median(dice_matrix[np.triu_indices(num_subjects, k=1)])\n",
    "\n",
    "# 随机化检验\n",
    "n_permutations = 1000  # 设置随机化次数\n",
    "permutation_medians = []\n",
    "\n",
    "# 执行随机化检验\n",
    "for _ in range(n_permutations):\n",
    "    # 创建一个副本，不影响原始数据\n",
    "    permuted_data = np.copy(subs_change_points)\n",
    "    \n",
    "    # 对每个被试独立打乱其变化点顺序\n",
    "    for i in range(num_subjects):\n",
    "        np.random.shuffle(permuted_data[i])  # 对每个被试的数据进行独立打乱\n",
    "    \n",
    "    # 重新计算随机化数据的Dice系数矩阵\n",
    "    permuted_dice_matrix = np.zeros((num_subjects, num_subjects))\n",
    "    for i in range(num_subjects):\n",
    "        for j in range(i, num_subjects):\n",
    "            intersection = np.sum(np.logical_and(permuted_data[i], permuted_data[j]))\n",
    "            union = np.sum(np.logical_or(permuted_data[i], permuted_data[j]))\n",
    "            permuted_dice_matrix[i, j] = 2 * intersection / (np.sum(permuted_data[i]) + np.sum(permuted_data[j]))\n",
    "            permuted_dice_matrix[j, i] = permuted_dice_matrix[i, j]\n",
    "    \n",
    "    # 计算随机化后的中位数Dice系数\n",
    "    permuted_median_dice = np.median(permuted_dice_matrix[np.triu_indices(num_subjects, k=1)])\n",
    "    permutation_medians.append(permuted_median_dice)\n",
    "\n",
    "# 计算p值\n",
    "permutation_medians = np.array(permutation_medians)\n",
    "p_value = np.mean(permutation_medians >= original_median_dice)\n",
    "\n",
    "# 输出原始中位数和p值\n",
    "print(f\"Original Median Dice Coefficient: {original_median_dice}\")\n",
    "print(f\"P-value from Randomization Test: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5cd954c5-2449-4dc3-95dc-aa7a8d7eed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Mean       Std       Min       Max    Median  25th Percentile  \\\n",
      "0  0.008885  0.000862  0.006172  0.012223  0.008831         0.008288   \n",
      "\n",
      "   75th Percentile  \n",
      "0         0.009449  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 计算描述统计数据\n",
    "desc_stats = {\n",
    "    'Mean': np.mean(permutation_means),\n",
    "    'Std': np.std(permutation_means),\n",
    "    'Min': np.min(permutation_means),\n",
    "    'Max': np.max(permutation_means),\n",
    "    'Median': np.median(permutation_means),\n",
    "    '25th Percentile': np.percentile(permutation_means, 25),\n",
    "    '75th Percentile': np.percentile(permutation_means, 75)\n",
    "}\n",
    "\n",
    "# 转换为 pandas DataFrame，方便查看\n",
    "desc_stats_df = pd.DataFrame([desc_stats])\n",
    "\n",
    "print(desc_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96d4e7f8-3629-437c-87e8-33910e5aca10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Mean Hamming Distance: 33.38438438438438\n",
      "P-value from Randomization Test: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_subjects = subs_change_points.shape[0]\n",
    "hamming_matrix = np.zeros((num_subjects, num_subjects))\n",
    "\n",
    "# 计算每对被试的汉明距离\n",
    "for i in range(num_subjects):\n",
    "    for j in range(i+1, num_subjects):\n",
    "        # 计算被试i和被试j之间的汉明距离\n",
    "        hamming_distance = np.sum(subs_change_points[i] != subs_change_points[j])  # 不同位置的数量\n",
    "        hamming_matrix[i, j] = hamming_distance\n",
    "        hamming_matrix[j, i] = hamming_distance  # 对称矩阵\n",
    "\n",
    "# 计算原始数据的平均汉明距离\n",
    "original_mean_hamming = np.mean(hamming_matrix[np.triu_indices(num_subjects, k=1)])\n",
    "print(f\"Original Mean Hamming Distance: {original_mean_hamming}\")\n",
    "\n",
    "# 随机化检验\n",
    "n_permutations = 1000  # 设置随机化次数\n",
    "permutation_means = []\n",
    "\n",
    "# 执行随机化检验\n",
    "for _ in range(n_permutations):\n",
    "    permuted_data = np.copy(subs_change_points)\n",
    "    \n",
    "    # 随机打乱每个被试的变化点\n",
    "    for i in range(num_subjects):\n",
    "        np.random.shuffle(permuted_data[i])  # 随机打乱每个被试的变化点顺序\n",
    "    \n",
    "    # 重新计算随机化数据的汉明距离矩阵\n",
    "    permuted_hamming_matrix = np.zeros((num_subjects, num_subjects))\n",
    "    for i in range(num_subjects):\n",
    "        for j in range(i+1, num_subjects):\n",
    "            permuted_hamming_distance = np.sum(permuted_data[i] != permuted_data[j])\n",
    "            permuted_hamming_matrix[i, j] = permuted_hamming_distance\n",
    "            permuted_hamming_matrix[j, i] = permuted_hamming_distance\n",
    "    \n",
    "    # 计算随机化后的平均汉明距离\n",
    "    permuted_mean_hamming = np.mean(permuted_hamming_matrix[np.triu_indices(num_subjects, k=1)])\n",
    "    permutation_means.append(permuted_mean_hamming)\n",
    "\n",
    "# 计算p值\n",
    "permutation_means = np.array(permutation_means)\n",
    "p_value = np.mean(permutation_means >= original_mean_hamming)\n",
    "\n",
    "print(f\"P-value from Randomization Test: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4526d040-7cc1-4f95-a530-09231359844d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01905419617094492"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_mean_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "758d9661-7946-4895-b59f-3a5fea86f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Mean       Std  Min       Max  Median  25th Percentile  75th Percentile\n",
      "0  0.019054  0.035401  0.0  0.285714     0.0              0.0         0.037393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_dice_counts = dice_matrix[np.triu_indices(num_subjects, k=1)]\n",
    "\n",
    "# 计算描述统计数据\n",
    "desc_stats = {\n",
    "    'Mean': np.mean(mean_dice_counts),\n",
    "    'Std': np.std(mean_dice_counts),\n",
    "    'Min': np.min(mean_dice_counts),\n",
    "    'Max': np.max(mean_dice_counts),\n",
    "    'Median': np.median(mean_dice_counts),\n",
    "    '25th Percentile': np.percentile(mean_dice_counts, 25),\n",
    "    '75th Percentile': np.percentile(mean_dice_counts, 75)\n",
    "}\n",
    "\n",
    "# 转换为 pandas DataFrame，方便查看\n",
    "desc_stats_df = pd.DataFrame([desc_stats])\n",
    "\n",
    "print(desc_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "231714ed-d492-4dc8-a676-238f52d02525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102102102102102"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_zeros = np.sum(np.array(mean_dice_counts) == 0) / len(mean_dice_counts)\n",
    "proportion_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "acd9ee39-10e8-4c13-a5c3-df9f2506ad16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_dice_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
