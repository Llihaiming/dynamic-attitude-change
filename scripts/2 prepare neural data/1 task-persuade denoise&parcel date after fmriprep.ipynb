{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92852476-e3f2-4d67-a407-23eef56c9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from nilearn import image, masking, input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778fc8b-146a-4713-b7e3-1d1fc9b16729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = '/Volumes/Li/task-persuade/braindata'\n",
    "denoised = 'denoised 5'\n",
    "\n",
    "fwhm=6\n",
    "tr = 2\n",
    "\n",
    "tmp = 'Schaefer'\n",
    "\n",
    "Schaefer_mask_file = '/Users/li/Desktop/template/Schaefer/tpl-MNI152NLin2009cAsym_res-02_atlas-Schaefer2018_desc-200Parcels7Networks_dseg.nii.gz'\n",
    "roi_label_file = '/Users/li/Desktop/template/Schaefer/Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm.Centroid_RAS.csv'\n",
    "Schaefer_mask = nib.load(Schaefer_mask_file)\n",
    "roi_label = pd.read_csv(roi_label_file)['ROI Name'].values.tolist()\n",
    "\n",
    "brain_mask_path = '/Users/li/Desktop/template/brain mask/tpl-MNI152NLin2009cAsym_res-02_desc-brain_mask.nii.gz'\n",
    "\n",
    "sub_list = [f'sub-{x:0>2d}' for x in range(1,36)]\n",
    "run_list = [1,2,3,4,5]\n",
    "\n",
    "for sub in sub_list:\n",
    "    new_folder_path = os.path.join(base_dir, denoised, 'denoised', sub)\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "\n",
    "    for run in run_list:\n",
    "        \n",
    "        run_file = f'/Volumes/Li/task-persuade/fmriprep/{sub}/func/{sub}_task-persuade_run-{run}_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz'\n",
    "        run_img = nib.load(run_file)\n",
    "        \n",
    "        confound_file = f'/Volumes/Li/task-persuade/fmriprep/{sub}/func/{sub}_task-persuade_run-{run}_desc-confounds_timeseries.tsv'\n",
    "        confound_df = pd.read_csv(confound_file, delimiter ='\\t')\n",
    "        \n",
    "        selected_confound_cols = ['csf','white_matter','global_signal',\n",
    "                                  'trans_x','trans_y','trans_z','rot_x','rot_y','rot_z',\n",
    "                                  'trans_x_derivative1','trans_y_derivative1','trans_z_derivative1',\n",
    "                                  'rot_x_derivative1','rot_y_derivative1','rot_z_derivative1',\n",
    "                                  # 'trans_x_power2','trans_y_power2','trans_z_power2',\n",
    "                                  # 'rot_x_power2','rot_y_power2','rot_z_power2',\n",
    "                                  # 'trans_x_derivative1_power2','trans_y_derivative1_power2','trans_z_derivative1_power2',\n",
    "                                  # 'rot_x_derivative1_power2','rot_y_derivative1_power2','rot_z_derivative1_power2'\n",
    "                                 ]\n",
    "        \n",
    "        confound_selected = confound_df[selected_confound_cols]\n",
    "        confound_selected = confound_selected.fillna(value=0)\n",
    "        confound_matrix = confound_selected.values\n",
    "\n",
    "        denoised_img = image.clean_img(run_img, confounds=confound_matrix,\n",
    "                                       detrend=True, standardize=True, high_pass=0.008, t_r=tr, mask_img=brain_mask_path)\n",
    "        \n",
    "        smoothed_img = image.smooth_img(denoised_img, fwhm=fwhm)\n",
    "        \n",
    "        save_path = os.path.join(base_dir, denoised, 'denoised', sub, f'{sub}_task-persuade_run-{run}_denoised_no_smooth_space-MNI152NLin2009cAsym_res-2_bold.nii.gz')\n",
    "        nib.save(smoothed_img,save_path)\n",
    "        # print(f'{sub} {run} denoised_smoothed data saved successfully!')\n",
    "\n",
    "    print(f'{sub} Done!')\n",
    "    print('-----------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80796c-4cdc-47bb-aadc-8dd7dbdb2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub in sub_list:\n",
    " \n",
    "    new_folder_path = os.path.join(base_dir, denoised, 'parcel data', tmp, sub)\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "\n",
    "    for run in run_list:\n",
    "\n",
    "        run_file = f'/Volumes/Li/task-persuade/braindata/{denoised}/denoised/{sub}/{sub}_task-persuade_run-{run}_denoised_no_smooth_space-MNI152NLin2009cAsym_res-2_bold.nii.gz'\n",
    "        run_image = nib.load(run_file)\n",
    "        \n",
    "        masker = input_data.NiftiLabelsMasker(labels_img = Schaefer_mask_file, standardize=True)\n",
    "        \n",
    "        parcellations_time_series = masker.fit_transform(run_image)\n",
    "        \n",
    "        parcellations_time_series_df = pd.DataFrame(parcellations_time_series) # , columns=roi_label\n",
    "        \n",
    "        \n",
    "        csv_file_path = f'/Volumes/Li/task-persuade/braindata/{denoised}/parcel data/{tmp}/{sub}/{sub}_run-{run}_task-persuade_{tmp}_time-series.csv'\n",
    "        parcellations_time_series_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    print(f'{sub} Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f4921-fea1-40a4-8ee1-f0f0c846d6f3",
   "metadata": {},
   "source": [
    "## note: The presentation order of experimental stimuli was counterbalanced using a Latin square design. \n",
    "## Subject 20 originally scheduled the session for the second day but missed it due to his oversleeping. He completed the experiment on the third day, following the stimulus order originally assigned for the second day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394aa83-1ab6-4846-82c7-faed2e9f8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_folder_path = os.path.join(base_dir, denoised, 'parcel data', 'Schaefer align 5 runs')\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.makedirs(new_folder_path)\n",
    "\n",
    "import itertools\n",
    "\n",
    "# sub-20 安排的是第二天，但睡过头了，没来，第三天另外加上的，但仍然按第二天安排的顺序做实验\n",
    "sub_lists = [['01','02','03','04','05','06','07'],\n",
    "             ['08','09',10,11,12,13,20],\n",
    "             [14,15,16,17,18,19,21],\n",
    "             [22,23,24,25,26,27,28],\n",
    "             [29,30,31,32,33,34,35]]\n",
    "\n",
    "# day1的run1对应day2的run5\n",
    "run_lists = [[1,2,3,4,5],\n",
    "            [5,1,2,3,4],\n",
    "            [4,5,1,2,3],\n",
    "            [3,4,5,1,2],\n",
    "            [2,3,4,5,1]]\n",
    "\n",
    "\n",
    "# time points\n",
    "time_lists = [[10,176,48,152,48,140,30],\n",
    " [10,134,48,162,48,168,30],\n",
    " [10,166,48,124,48,182,30],\n",
    " [10,138,48,132,48,188,30],\n",
    " [10,170,48,150,48,148,30]]\n",
    "\n",
    "# 计算累加时间,转成TR数\n",
    "tr_lists = [[int(x/2) for x in itertools.accumulate(sublist)] for sublist in time_lists]\n",
    "\n",
    "\n",
    "# 把15个片段的数据拼接起来\n",
    "\n",
    "subs_data = []\n",
    "\n",
    "for day in list(range(5)):\n",
    "    \n",
    "    for sub in sub_lists[day]:\n",
    "        sub_data = []\n",
    "        \n",
    "        for index,run in enumerate(run_lists[day]):\n",
    "            \n",
    "            tr = tr_lists[index]\n",
    "            file = f'/Volumes/Li/task-persuade/braindata/{denoised}/parcel data/{tmp}/sub-{sub}/sub-{sub}_run-{run}_task-persuade_{tmp}_time-series.csv'\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # 分别提取三段视频的BOLD\n",
    "            run_data = np.array(pd.concat([df.iloc[tr[0]:tr[1]], \n",
    "                                           df.iloc[tr[2]:tr[3]], \n",
    "                                           df.iloc[tr[4]+1:tr[5]+1]]))   # For the third video in each run, the onset time was manually adjusted due to a delay in the program.\n",
    "            sub_data.append(run_data)\n",
    "        sub_data = np.vstack(sub_data)\n",
    "        subs_data.append(sub_data)\n",
    "        \n",
    "subs_data = np.array(subs_data)\n",
    "print(subs_data.shape)\n",
    "\n",
    "np.save(f'/Volumes/Li/task-persuade/braindata/{denoised}/parcel data/Schaefer align 5 runs/subs_data.npy', subs_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
